# Spark
Spark Projects

The fundamental features of this script Pyspark, Sparksql and Mongodb are used. 

-->Firstly, neccessary packages are imported, spark configuration is set up and then spark session is started.
-->The dataframe of tables are created. Some transformations are made  with spark sql commands. Then the final data is written to a directory.
-->Finally, mongodb connection is created and final data is loaded to mongodb colllection.

